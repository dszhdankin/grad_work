{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30cbdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "333289c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/daniil/.cache/huggingface/datasets/csv/default-2a679b917dd5f579/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859c262235ae4ba78bfb1ba0f8cc7e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'sql'],\n",
       "        num_rows: 9428\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_processed_dataset = load_dataset(\"csv\", data_files=\"datasets/BIRD/train/train_initial.csv\")\n",
    "\n",
    "bird_processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebbcc480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'sql'],\n",
       "        num_rows: 7504\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'sql'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'sql'],\n",
       "        num_rows: 262\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_train_test = bird_processed_dataset[\"train\"].train_test_split(test_size=262)\n",
    "datasets_train_validation = datasets_train_test[\"train\"].train_test_split(test_size=700)\n",
    "\n",
    "bird_processed_dataset[\"train\"] = datasets_train_validation[\"train\"]\n",
    "bird_processed_dataset[\"validation\"] = datasets_train_validation[\"test\"]\n",
    "bird_processed_dataset[\"test\"] = datasets_train_test[\"test\"]\n",
    "\n",
    "bird_processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea105fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daniil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_pretrained = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_pretrained, model_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfd2b9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'sql'],\n",
       "        num_rows: 7504\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'sql'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'sql'],\n",
       "        num_rows: 262\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_processed_dataset[\"train\"] = bird_processed_dataset[\"train\"].shuffle()\n",
    "bird_processed_dataset[\"validation\"] = bird_processed_dataset[\"validation\"].shuffle()\n",
    "bird_processed_dataset[\"test\"] = bird_processed_dataset[\"test\"].shuffle()\n",
    "\n",
    "bird_processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "299b4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"translate English to SQL \"\n",
    "max_input_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "def prepare_data(examples):\n",
    "    inputs = [prefix + text for text in examples[\"question\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    \n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"sql\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f47e743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/torch/graduation-work/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = bird_processed_dataset.map(prepare_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "500d112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7caa36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_name = \"t5-small-english-to-sql-bird-translation\"\n",
    "model_dir = f\"models/{model_name}\"\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    model_dir,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    learning_rate=8e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=8,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"bleu\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81544da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5632/648691721.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"bleu\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "\n",
    "metric = load_metric(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, references = eval_pred\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    predictions = [pred.split() for pred in predictions]\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    references = np.where(references != -100, references, tokenizer.pad_token_id)\n",
    "    references = tokenizer.batch_decode(references, skip_special_tokens=True)\n",
    "    references = [ref.split() for ref in references]\n",
    "    references = [[ref] for ref in references]\n",
    "    \n",
    "    \n",
    "    # Compute BLEU scores\n",
    "    result = metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e663b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns an untrained model to be trained\n",
    "def model_init():\n",
    "    return AutoModelForSeq2SeqLM.from_pretrained(model_pretrained)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "baa8b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5676), started 0:04:29 ago. (Use '!kill 5676' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start TensorBoard before training to monitor it in progress\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '{model_dir}'/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52cfaa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/torch/graduation-work/venv/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7504' max='7504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7504/7504 29:57, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Precisions</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>2.236026</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>[0.3135593220338983, 0.06330087134802666, 0.024359775140537165, 0.012688342585249802]</td>\n",
       "      <td>0.059085</td>\n",
       "      <td>0.261180</td>\n",
       "      <td>4602</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.322400</td>\n",
       "      <td>1.755156</td>\n",
       "      <td>0.039452</td>\n",
       "      <td>[0.5778282746307417, 0.28090093389489107, 0.208779668136946, 0.12168792934249265]</td>\n",
       "      <td>0.155684</td>\n",
       "      <td>0.349659</td>\n",
       "      <td>6161</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.013800</td>\n",
       "      <td>1.548743</td>\n",
       "      <td>0.035521</td>\n",
       "      <td>[0.5925305643945737, 0.28059191804211725, 0.20126886895646467, 0.11654232055569848]</td>\n",
       "      <td>0.142142</td>\n",
       "      <td>0.338876</td>\n",
       "      <td>5971</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.788600</td>\n",
       "      <td>1.437320</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>[0.5970149253731343, 0.2872420262664165, 0.20647948164146868, 0.12039624079248158]</td>\n",
       "      <td>0.146306</td>\n",
       "      <td>0.342225</td>\n",
       "      <td>6030</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.680100</td>\n",
       "      <td>1.351371</td>\n",
       "      <td>0.035515</td>\n",
       "      <td>[0.592462311557789, 0.2806451612903226, 0.20021881838074398, 0.11729827275070895]</td>\n",
       "      <td>0.142072</td>\n",
       "      <td>0.338820</td>\n",
       "      <td>5970</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.599100</td>\n",
       "      <td>1.278411</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>[0.5928023992002666, 0.27706525839305923, 0.19556714471968709, 0.11216389244558259]</td>\n",
       "      <td>0.144325</td>\n",
       "      <td>0.340636</td>\n",
       "      <td>6002</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.494600</td>\n",
       "      <td>1.230341</td>\n",
       "      <td>0.035957</td>\n",
       "      <td>[0.5896460469732054, 0.2759072203516648, 0.1941455015066724, 0.11198378515328097]</td>\n",
       "      <td>0.147442</td>\n",
       "      <td>0.343133</td>\n",
       "      <td>6046</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.474600</td>\n",
       "      <td>1.186313</td>\n",
       "      <td>0.035451</td>\n",
       "      <td>[0.5947679324894515, 0.2872727272727273, 0.20508287292817678, 0.12101411395713539]</td>\n",
       "      <td>0.138922</td>\n",
       "      <td>0.336266</td>\n",
       "      <td>5925</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.425500</td>\n",
       "      <td>1.145833</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>[0.5968870234347674, 0.28736548425667596, 0.20078740157480315, 0.11350455675227837]</td>\n",
       "      <td>0.124743</td>\n",
       "      <td>0.324518</td>\n",
       "      <td>5718</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.357600</td>\n",
       "      <td>1.118350</td>\n",
       "      <td>0.034597</td>\n",
       "      <td>[0.5969257045260461, 0.2892337536372454, 0.20763187429854096, 0.12370311252992817]</td>\n",
       "      <td>0.134070</td>\n",
       "      <td>0.332293</td>\n",
       "      <td>5855</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.320600</td>\n",
       "      <td>1.092135</td>\n",
       "      <td>0.028190</td>\n",
       "      <td>[0.6044654202214558, 0.29008109794135994, 0.2029690922365539, 0.1169744942832014]</td>\n",
       "      <td>0.110980</td>\n",
       "      <td>0.312656</td>\n",
       "      <td>5509</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.311300</td>\n",
       "      <td>1.062621</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>[0.5984700231275574, 0.28937207884576305, 0.2023217247097844, 0.11968235961429381]</td>\n",
       "      <td>0.118283</td>\n",
       "      <td>0.319012</td>\n",
       "      <td>5621</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.295600</td>\n",
       "      <td>1.033343</td>\n",
       "      <td>0.028720</td>\n",
       "      <td>[0.5984138428262437, 0.28816006600660066, 0.20106075216972036, 0.11822660098522167]</td>\n",
       "      <td>0.113504</td>\n",
       "      <td>0.314869</td>\n",
       "      <td>5548</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.244900</td>\n",
       "      <td>1.017652</td>\n",
       "      <td>0.029852</td>\n",
       "      <td>[0.5970042796005706, 0.28748981255093725, 0.20247148288973385, 0.12019367701509541]</td>\n",
       "      <td>0.117427</td>\n",
       "      <td>0.318275</td>\n",
       "      <td>5608</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.213700</td>\n",
       "      <td>0.996626</td>\n",
       "      <td>0.029663</td>\n",
       "      <td>[0.6002883402414849, 0.29325634151371416, 0.20727886237647625, 0.12753623188405797]</td>\n",
       "      <td>0.113569</td>\n",
       "      <td>0.314926</td>\n",
       "      <td>5549</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.219800</td>\n",
       "      <td>0.974440</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>[0.597718071402282, 0.286227291930714, 0.20004957858205255, 0.1211031175059952]</td>\n",
       "      <td>0.106188</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>5434</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.177300</td>\n",
       "      <td>0.961580</td>\n",
       "      <td>0.027804</td>\n",
       "      <td>[0.601651376146789, 0.29410526315789476, 0.20666666666666667, 0.12373285629099583]</td>\n",
       "      <td>0.107203</td>\n",
       "      <td>0.309308</td>\n",
       "      <td>5450</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.163000</td>\n",
       "      <td>0.942586</td>\n",
       "      <td>0.027886</td>\n",
       "      <td>[0.5997805011889519, 0.29032934759807005, 0.20211458077206787, 0.12496289700207777]</td>\n",
       "      <td>0.108287</td>\n",
       "      <td>0.310272</td>\n",
       "      <td>5467</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.142900</td>\n",
       "      <td>0.933123</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>[0.6016438356164383, 0.29340314136125656, 0.20368098159509201, 0.12466686408054486]</td>\n",
       "      <td>0.108798</td>\n",
       "      <td>0.310726</td>\n",
       "      <td>5475</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.084700</td>\n",
       "      <td>0.916055</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>[0.6021994690936671, 0.2916484477481417, 0.2041817243159525, 0.1261799874134676]</td>\n",
       "      <td>0.096239</td>\n",
       "      <td>0.299319</td>\n",
       "      <td>5274</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.097400</td>\n",
       "      <td>0.902868</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>[0.6051178203240059, 0.2960693153000845, 0.20709325396825398, 0.126874625074985]</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.308286</td>\n",
       "      <td>5432</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.102700</td>\n",
       "      <td>0.889806</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>[0.6074101796407185, 0.3023255813953488, 0.21475659229208924, 0.1337030191004313]</td>\n",
       "      <td>0.100544</td>\n",
       "      <td>0.303292</td>\n",
       "      <td>5344</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.076300</td>\n",
       "      <td>0.878275</td>\n",
       "      <td>0.026092</td>\n",
       "      <td>[0.6052631578947368, 0.29653679653679654, 0.2076530612244898, 0.12915243713132568]</td>\n",
       "      <td>0.099060</td>\n",
       "      <td>0.301930</td>\n",
       "      <td>5320</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.087400</td>\n",
       "      <td>0.866609</td>\n",
       "      <td>0.027238</td>\n",
       "      <td>[0.6072490706319703, 0.2989316239316239, 0.20879396984924622, 0.13010359536867763]</td>\n",
       "      <td>0.102787</td>\n",
       "      <td>0.305335</td>\n",
       "      <td>5380</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.055400</td>\n",
       "      <td>0.855446</td>\n",
       "      <td>0.026967</td>\n",
       "      <td>[0.6094740768370012, 0.29922779922779924, 0.20898536092882383, 0.12990196078431374]</td>\n",
       "      <td>0.101663</td>\n",
       "      <td>0.304313</td>\n",
       "      <td>5362</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.042300</td>\n",
       "      <td>0.845378</td>\n",
       "      <td>0.025769</td>\n",
       "      <td>[0.6123691722169362, 0.3034028540065862, 0.21374837872892347, 0.1358454718176061]</td>\n",
       "      <td>0.095084</td>\n",
       "      <td>0.298241</td>\n",
       "      <td>5255</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.030500</td>\n",
       "      <td>0.839542</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>[0.6155853840417599, 0.3059605488850772, 0.21417759838546924, 0.13511029411764705]</td>\n",
       "      <td>0.101788</td>\n",
       "      <td>0.304427</td>\n",
       "      <td>5364</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.031000</td>\n",
       "      <td>0.831998</td>\n",
       "      <td>0.028342</td>\n",
       "      <td>[0.6138430135461125, 0.30624866709319687, 0.21759839558786664, 0.13825584928593132]</td>\n",
       "      <td>0.103351</td>\n",
       "      <td>0.305846</td>\n",
       "      <td>5389</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.980800</td>\n",
       "      <td>0.823557</td>\n",
       "      <td>0.028252</td>\n",
       "      <td>[0.6181513231457324, 0.31268752678954137, 0.21986888552697934, 0.13896541169268442]</td>\n",
       "      <td>0.101913</td>\n",
       "      <td>0.304540</td>\n",
       "      <td>5366</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.815645</td>\n",
       "      <td>0.027021</td>\n",
       "      <td>[0.6112981668537224, 0.2993973310374516, 0.21211353269133298, 0.1337030191004313]</td>\n",
       "      <td>0.100669</td>\n",
       "      <td>0.303405</td>\n",
       "      <td>5346</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.975800</td>\n",
       "      <td>0.808427</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>[0.6178451178451179, 0.3056392595781317, 0.21743537759756715, 0.13639162561576354]</td>\n",
       "      <td>0.100669</td>\n",
       "      <td>0.303405</td>\n",
       "      <td>5346</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.994200</td>\n",
       "      <td>0.796866</td>\n",
       "      <td>0.026737</td>\n",
       "      <td>[0.6183364839319471, 0.30915032679738563, 0.21825192802056556, 0.13713212273011896]</td>\n",
       "      <td>0.097217</td>\n",
       "      <td>0.300227</td>\n",
       "      <td>5290</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>0.796508</td>\n",
       "      <td>0.028890</td>\n",
       "      <td>[0.6236258617477175, 0.31733447610884935, 0.22586337282581295, 0.144124847001224]</td>\n",
       "      <td>0.101975</td>\n",
       "      <td>0.304597</td>\n",
       "      <td>5367</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.980100</td>\n",
       "      <td>0.786176</td>\n",
       "      <td>0.028193</td>\n",
       "      <td>[0.6231071228266966, 0.31662723166272316, 0.22106862496834642, 0.14]</td>\n",
       "      <td>0.100855</td>\n",
       "      <td>0.303575</td>\n",
       "      <td>5349</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.958700</td>\n",
       "      <td>0.782415</td>\n",
       "      <td>0.028815</td>\n",
       "      <td>[0.626238086339002, 0.3203612126424425, 0.22728423184004048, 0.14540424223793422]</td>\n",
       "      <td>0.100979</td>\n",
       "      <td>0.303689</td>\n",
       "      <td>5351</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.939400</td>\n",
       "      <td>0.774614</td>\n",
       "      <td>0.027526</td>\n",
       "      <td>[0.6238185255198487, 0.31808278867102396, 0.22467866323907454, 0.14415543716703227]</td>\n",
       "      <td>0.097217</td>\n",
       "      <td>0.300227</td>\n",
       "      <td>5290</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.954600</td>\n",
       "      <td>0.767477</td>\n",
       "      <td>0.028786</td>\n",
       "      <td>[0.6265015015015015, 0.32476231633535, 0.23065173116089613, 0.14896252709817281]</td>\n",
       "      <td>0.099554</td>\n",
       "      <td>0.302384</td>\n",
       "      <td>5328</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.935900</td>\n",
       "      <td>0.765053</td>\n",
       "      <td>0.028239</td>\n",
       "      <td>[0.6250470809792844, 0.3249457700650759, 0.22915601023017904, 0.1454828660436137]</td>\n",
       "      <td>0.098444</td>\n",
       "      <td>0.301362</td>\n",
       "      <td>5310</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.758236</td>\n",
       "      <td>0.028087</td>\n",
       "      <td>[0.6249764195434824, 0.3229732666811563, 0.22865931812355805, 0.14682911590128084]</td>\n",
       "      <td>0.097891</td>\n",
       "      <td>0.300851</td>\n",
       "      <td>5301</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.753388</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>[0.6268183513614323, 0.3234663234663235, 0.22690560323069156, 0.14561618638871857]</td>\n",
       "      <td>0.101663</td>\n",
       "      <td>0.304313</td>\n",
       "      <td>5362</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.910800</td>\n",
       "      <td>0.750979</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>[0.6248835909852859, 0.3238380809595202, 0.23230032753842278, 0.15045871559633028]</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.304711</td>\n",
       "      <td>5369</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.904500</td>\n",
       "      <td>0.747609</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>[0.6275720164609053, 0.3269479121825226, 0.23289406994424733, 0.15332512315270935]</td>\n",
       "      <td>0.100669</td>\n",
       "      <td>0.303405</td>\n",
       "      <td>5346</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.743543</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>[0.6296996032495749, 0.330720661876769, 0.23632160287695864, 0.15685660613650595]</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.300397</td>\n",
       "      <td>5293</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.906500</td>\n",
       "      <td>0.738611</td>\n",
       "      <td>0.028637</td>\n",
       "      <td>[0.6313607237090086, 0.3282674772036474, 0.231694828469022, 0.15060804490177737]</td>\n",
       "      <td>0.098198</td>\n",
       "      <td>0.301135</td>\n",
       "      <td>5306</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.896600</td>\n",
       "      <td>0.735416</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>[0.6287694324779921, 0.32593231299849107, 0.22899212998222898, 0.14969135802469136]</td>\n",
       "      <td>0.100234</td>\n",
       "      <td>0.303008</td>\n",
       "      <td>5339</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.892900</td>\n",
       "      <td>0.730099</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>[0.6303975651512269, 0.32675005486065395, 0.23049001814882034, 0.15072830905636478]</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>0.298354</td>\n",
       "      <td>5257</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.874400</td>\n",
       "      <td>0.728009</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>[0.6278009874667679, 0.32588699080157685, 0.23176409725814795, 0.1509314808967477]</td>\n",
       "      <td>0.095752</td>\n",
       "      <td>0.298865</td>\n",
       "      <td>5266</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.724669</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>[0.6315199102636007, 0.33426543342654336, 0.23828817422132184, 0.15569230769230769]</td>\n",
       "      <td>0.100855</td>\n",
       "      <td>0.303575</td>\n",
       "      <td>5349</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.721001</td>\n",
       "      <td>0.029302</td>\n",
       "      <td>[0.6333396333396334, 0.33587453713787846, 0.24081213055769726, 0.16071428571428573]</td>\n",
       "      <td>0.097278</td>\n",
       "      <td>0.300284</td>\n",
       "      <td>5291</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.844300</td>\n",
       "      <td>0.720936</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>[0.630656108597285, 0.32971329278887923, 0.2336065573770492, 0.15226209048361936]</td>\n",
       "      <td>0.098075</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>5304</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>0.713711</td>\n",
       "      <td>0.028549</td>\n",
       "      <td>[0.6345824614799315, 0.3353083168751371, 0.2390458905885403, 0.15896136795440152]</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>0.298354</td>\n",
       "      <td>5257</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.852400</td>\n",
       "      <td>0.712679</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>[0.6321292775665399, 0.33223684210526316, 0.23626943005181347, 0.15691236950332174]</td>\n",
       "      <td>0.095387</td>\n",
       "      <td>0.298524</td>\n",
       "      <td>5260</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.895800</td>\n",
       "      <td>0.709147</td>\n",
       "      <td>0.028517</td>\n",
       "      <td>[0.6323278315310188, 0.33099978122949025, 0.23688969258589512, 0.15668348045397226]</td>\n",
       "      <td>0.096056</td>\n",
       "      <td>0.299149</td>\n",
       "      <td>5271</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.863400</td>\n",
       "      <td>0.709157</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>[0.6342294585384324, 0.33915320820602357, 0.243946419371458, 0.16153362664990573]</td>\n",
       "      <td>0.096727</td>\n",
       "      <td>0.299773</td>\n",
       "      <td>5282</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.705577</td>\n",
       "      <td>0.029854</td>\n",
       "      <td>[0.6333583771600301, 0.3375865051903114, 0.2400611620795107, 0.15911910669975185]</td>\n",
       "      <td>0.099307</td>\n",
       "      <td>0.302157</td>\n",
       "      <td>5324</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.703669</td>\n",
       "      <td>0.029656</td>\n",
       "      <td>[0.6333521550912855, 0.33600693691740735, 0.23971377459749552, 0.16023646546359677]</td>\n",
       "      <td>0.098629</td>\n",
       "      <td>0.301532</td>\n",
       "      <td>5313</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.819400</td>\n",
       "      <td>0.702375</td>\n",
       "      <td>0.029505</td>\n",
       "      <td>[0.6367254121660034, 0.34083460782171726, 0.2450348207376838, 0.16488357457520453]</td>\n",
       "      <td>0.096422</td>\n",
       "      <td>0.299489</td>\n",
       "      <td>5277</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>0.698973</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>[0.6344228225958813, 0.33834095362508165, 0.24197277164140765, 0.16343143393863493]</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.300397</td>\n",
       "      <td>5293</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.697642</td>\n",
       "      <td>0.030108</td>\n",
       "      <td>[0.6358338033464938, 0.33795193764884174, 0.24317427915284512, 0.16371543957750853]</td>\n",
       "      <td>0.098998</td>\n",
       "      <td>0.301873</td>\n",
       "      <td>5319</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>0.694841</td>\n",
       "      <td>0.029317</td>\n",
       "      <td>[0.6339437417406079, 0.334130954970633, 0.23915832691814215, 0.16041275797373358]</td>\n",
       "      <td>0.097646</td>\n",
       "      <td>0.300624</td>\n",
       "      <td>5297</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.695015</td>\n",
       "      <td>0.029170</td>\n",
       "      <td>[0.6357075023741691, 0.33997809419496167, 0.24372574385510995, 0.16392924826279218]</td>\n",
       "      <td>0.095691</td>\n",
       "      <td>0.298808</td>\n",
       "      <td>5265</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.836900</td>\n",
       "      <td>0.692997</td>\n",
       "      <td>0.029473</td>\n",
       "      <td>[0.6362773029439696, 0.3417305585980285, 0.2463130659767141, 0.16803537586860393]</td>\n",
       "      <td>0.095691</td>\n",
       "      <td>0.298808</td>\n",
       "      <td>5265</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.691926</td>\n",
       "      <td>0.029725</td>\n",
       "      <td>[0.6370692919348732, 0.3419903972064601, 0.24678001030396704, 0.16588124410933083]</td>\n",
       "      <td>0.096727</td>\n",
       "      <td>0.299773</td>\n",
       "      <td>5282</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.837800</td>\n",
       "      <td>0.690199</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>[0.6382252559726962, 0.344993441189331, 0.2483221476510067, 0.16787401574803149]</td>\n",
       "      <td>0.096239</td>\n",
       "      <td>0.299319</td>\n",
       "      <td>5274</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.830800</td>\n",
       "      <td>0.688538</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>[0.633965844402277, 0.34070021881838075, 0.24444444444444444, 0.16461684011352887]</td>\n",
       "      <td>0.095996</td>\n",
       "      <td>0.299092</td>\n",
       "      <td>5270</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.029415</td>\n",
       "      <td>[0.6371933827723902, 0.34459311252467645, 0.24850997667789582, 0.1661392405063291]</td>\n",
       "      <td>0.095327</td>\n",
       "      <td>0.298468</td>\n",
       "      <td>5259</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.816800</td>\n",
       "      <td>0.686760</td>\n",
       "      <td>0.029476</td>\n",
       "      <td>[0.6359490784723542, 0.3431952662721893, 0.2479937872120114, 0.16719342604298357]</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.298695</td>\n",
       "      <td>5263</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.838900</td>\n",
       "      <td>0.686812</td>\n",
       "      <td>0.030037</td>\n",
       "      <td>[0.6378787878787879, 0.3465065502183406, 0.25, 0.16912920465262496]</td>\n",
       "      <td>0.096605</td>\n",
       "      <td>0.299659</td>\n",
       "      <td>5280</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.840100</td>\n",
       "      <td>0.685564</td>\n",
       "      <td>0.030008</td>\n",
       "      <td>[0.6350737797956867, 0.34496293065852596, 0.24935666495110653, 0.16786946972074052]</td>\n",
       "      <td>0.096972</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5286</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.821600</td>\n",
       "      <td>0.684555</td>\n",
       "      <td>0.029880</td>\n",
       "      <td>[0.6363636363636364, 0.3447598253275109, 0.24896907216494846, 0.1675573718956303]</td>\n",
       "      <td>0.096605</td>\n",
       "      <td>0.299659</td>\n",
       "      <td>5280</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.820700</td>\n",
       "      <td>0.683516</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>[0.6362431357697406, 0.34468456668849595, 0.2478742592115434, 0.1671904462602137]</td>\n",
       "      <td>0.096666</td>\n",
       "      <td>0.299716</td>\n",
       "      <td>5281</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.807300</td>\n",
       "      <td>0.683086</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>[0.6355547141234381, 0.34329986905281534, 0.24781040700669757, 0.16750471401634193]</td>\n",
       "      <td>0.096727</td>\n",
       "      <td>0.299773</td>\n",
       "      <td>5282</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>[0.6362947527940898, 0.34439834024896265, 0.2477442639855633, 0.1667190940547342]</td>\n",
       "      <td>0.096544</td>\n",
       "      <td>0.299603</td>\n",
       "      <td>5279</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.806200</td>\n",
       "      <td>0.682536</td>\n",
       "      <td>0.029860</td>\n",
       "      <td>[0.6355034065102195, 0.343586387434555, 0.24768280123583933, 0.1670854271356784]</td>\n",
       "      <td>0.096850</td>\n",
       "      <td>0.299886</td>\n",
       "      <td>5284</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.682532</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>[0.6350226928895613, 0.3432868352223191, 0.24742798353909465, 0.1668757841907152]</td>\n",
       "      <td>0.097094</td>\n",
       "      <td>0.300114</td>\n",
       "      <td>5288</td>\n",
       "      <td>17620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.3135593220338983, 0.06330087134802666, 0.024359775140537165, 0.012688342585249802]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5778282746307417, 0.28090093389489107, 0.208779668136946, 0.12168792934249265]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5925305643945737, 0.28059191804211725, 0.20126886895646467, 0.11654232055569848]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5970149253731343, 0.2872420262664165, 0.20647948164146868, 0.12039624079248158]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.592462311557789, 0.2806451612903226, 0.20021881838074398, 0.11729827275070895]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5928023992002666, 0.27706525839305923, 0.19556714471968709, 0.11216389244558259]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5896460469732054, 0.2759072203516648, 0.1941455015066724, 0.11198378515328097]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5947679324894515, 0.2872727272727273, 0.20508287292817678, 0.12101411395713539]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5968870234347674, 0.28736548425667596, 0.20078740157480315, 0.11350455675227837]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5969257045260461, 0.2892337536372454, 0.20763187429854096, 0.12370311252992817]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6044654202214558, 0.29008109794135994, 0.2029690922365539, 0.1169744942832014]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5984700231275574, 0.28937207884576305, 0.2023217247097844, 0.11968235961429381]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5984138428262437, 0.28816006600660066, 0.20106075216972036, 0.11822660098522167]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5970042796005706, 0.28748981255093725, 0.20247148288973385, 0.12019367701509541]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6002883402414849, 0.29325634151371416, 0.20727886237647625, 0.12753623188405797]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.597718071402282, 0.286227291930714, 0.20004957858205255, 0.1211031175059952]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.601651376146789, 0.29410526315789476, 0.20666666666666667, 0.12373285629099583]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.5997805011889519, 0.29032934759807005, 0.20211458077206787, 0.12496289700207777]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6016438356164383, 0.29340314136125656, 0.20368098159509201, 0.12466686408054486]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6021994690936671, 0.2916484477481417, 0.2041817243159525, 0.1261799874134676]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6051178203240059, 0.2960693153000845, 0.20709325396825398, 0.126874625074985]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6074101796407185, 0.3023255813953488, 0.21475659229208924, 0.1337030191004313]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6052631578947368, 0.29653679653679654, 0.2076530612244898, 0.12915243713132568]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6072490706319703, 0.2989316239316239, 0.20879396984924622, 0.13010359536867763]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6094740768370012, 0.29922779922779924, 0.20898536092882383, 0.12990196078431374]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6123691722169362, 0.3034028540065862, 0.21374837872892347, 0.1358454718176061]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6155853840417599, 0.3059605488850772, 0.21417759838546924, 0.13511029411764705]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6138430135461125, 0.30624866709319687, 0.21759839558786664, 0.13825584928593132]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6181513231457324, 0.31268752678954137, 0.21986888552697934, 0.13896541169268442]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.6112981668537224, 0.2993973310374516, 0.21211353269133298, 0.1337030191004313]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6178451178451179, 0.3056392595781317, 0.21743537759756715, 0.13639162561576354]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6183364839319471, 0.30915032679738563, 0.21825192802056556, 0.13713212273011896]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6236258617477175, 0.31733447610884935, 0.22586337282581295, 0.144124847001224]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6231071228266966, 0.31662723166272316, 0.22106862496834642, 0.14]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.626238086339002, 0.3203612126424425, 0.22728423184004048, 0.14540424223793422]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6238185255198487, 0.31808278867102396, 0.22467866323907454, 0.14415543716703227]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6265015015015015, 0.32476231633535, 0.23065173116089613, 0.14896252709817281]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6250470809792844, 0.3249457700650759, 0.22915601023017904, 0.1454828660436137]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6249764195434824, 0.3229732666811563, 0.22865931812355805, 0.14682911590128084]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6268183513614323, 0.3234663234663235, 0.22690560323069156, 0.14561618638871857]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6248835909852859, 0.3238380809595202, 0.23230032753842278, 0.15045871559633028]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6275720164609053, 0.3269479121825226, 0.23289406994424733, 0.15332512315270935]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6296996032495749, 0.330720661876769, 0.23632160287695864, 0.15685660613650595]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6313607237090086, 0.3282674772036474, 0.231694828469022, 0.15060804490177737]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6287694324779921, 0.32593231299849107, 0.22899212998222898, 0.14969135802469136]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6303975651512269, 0.32675005486065395, 0.23049001814882034, 0.15072830905636478]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6278009874667679, 0.32588699080157685, 0.23176409725814795, 0.1509314808967477]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6315199102636007, 0.33426543342654336, 0.23828817422132184, 0.15569230769230769]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6333396333396334, 0.33587453713787846, 0.24081213055769726, 0.16071428571428573]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.630656108597285, 0.32971329278887923, 0.2336065573770492, 0.15226209048361936]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6345824614799315, 0.3353083168751371, 0.2390458905885403, 0.15896136795440152]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6321292775665399, 0.33223684210526316, 0.23626943005181347, 0.15691236950332174]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6323278315310188, 0.33099978122949025, 0.23688969258589512, 0.15668348045397226]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6342294585384324, 0.33915320820602357, 0.243946419371458, 0.16153362664990573]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6333583771600301, 0.3375865051903114, 0.2400611620795107, 0.15911910669975185]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6333521550912855, 0.33600693691740735, 0.23971377459749552, 0.16023646546359677]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6367254121660034, 0.34083460782171726, 0.2450348207376838, 0.16488357457520453]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6344228225958813, 0.33834095362508165, 0.24197277164140765, 0.16343143393863493]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6358338033464938, 0.33795193764884174, 0.24317427915284512, 0.16371543957750853]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.6339437417406079, 0.334130954970633, 0.23915832691814215, 0.16041275797373358]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6357075023741691, 0.33997809419496167, 0.24372574385510995, 0.16392924826279218]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6362773029439696, 0.3417305585980285, 0.2463130659767141, 0.16803537586860393]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6370692919348732, 0.3419903972064601, 0.24678001030396704, 0.16588124410933083]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6382252559726962, 0.344993441189331, 0.2483221476510067, 0.16787401574803149]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.633965844402277, 0.34070021881838075, 0.24444444444444444, 0.16461684011352887]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6371933827723902, 0.34459311252467645, 0.24850997667789582, 0.1661392405063291]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6359490784723542, 0.3431952662721893, 0.2479937872120114, 0.16719342604298357]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6378787878787879, 0.3465065502183406, 0.25, 0.16912920465262496]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6350737797956867, 0.34496293065852596, 0.24935666495110653, 0.16786946972074052]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6363636363636364, 0.3447598253275109, 0.24896907216494846, 0.1675573718956303]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6362431357697406, 0.34468456668849595, 0.2478742592115434, 0.1671904462602137]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6355547141234381, 0.34329986905281534, 0.24781040700669757, 0.16750471401634193]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6362947527940898, 0.34439834024896265, 0.2477442639855633, 0.1667190940547342]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6355034065102195, 0.343586387434555, 0.24768280123583933, 0.1670854271356784]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.6350226928895613, 0.3432868352223191, 0.24742798353909465, 0.1668757841907152]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7504, training_loss=1.0775056307885185, metrics={'train_runtime': 1799.0405, 'train_samples_per_second': 33.369, 'train_steps_per_second': 4.171, 'total_flos': 556692550189056.0, 'train_loss': 1.0775056307885185, 'epoch': 8.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec9da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-small-english-to-sql-bird-translation/checkpoint-10000\"\n",
    "model_dir = f\"models/{model_name}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "max_input_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e98a65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT T2.title FROM movie AS T1 INNER JOIN movie_platform AS T2 ON T1.movie_id = T2.movie_id WHERE T1.movie_title = 'Last'\n"
     ]
    }
   ],
   "source": [
    "text = \"for movie_platform database: What is the name of the longest movie title? When was it released?\"\n",
    "\n",
    "inputs = [\"translate English to SQL \" + text]\n",
    "\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=4, max_length=128)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_query = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_query) # SELECT movie_title, movie_release_year FROM movies ORDER BY LENGTH(movie_popularity) DESC LIMIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7ba62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
