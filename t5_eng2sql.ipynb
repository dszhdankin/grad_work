{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1043f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c271a84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/daniil/.cache/huggingface/datasets/csv/default-6466c2472f5c33b7/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0267b4bd189e45a3b6989b4dbd725d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'human_sql'],\n",
       "        num_rows: 56092\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikisql_processed_dataset = load_dataset(\"csv\", data_files=\"datasets/eng2SQL.csv\")\n",
    "\n",
    "wikisql_processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e902487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'human_sql'],\n",
       "        num_rows: 52092\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'human_sql'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'human_sql'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_train_test = wikisql_processed_dataset[\"train\"].train_test_split(test_size=2000)\n",
    "datasets_train_validation = datasets_train_test[\"train\"].train_test_split(test_size=2000)\n",
    "\n",
    "wikisql_processed_dataset[\"train\"] = datasets_train_validation[\"train\"]\n",
    "wikisql_processed_dataset[\"validation\"] = datasets_train_validation[\"test\"]\n",
    "wikisql_processed_dataset[\"test\"] = datasets_train_test[\"test\"]\n",
    "\n",
    "wikisql_processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a8f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daniil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, model_max_length=512)\n",
    "print(type(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd9eb60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'human_sql'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'human_sql'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'human_sql'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only a subsample of the datasets\n",
    "wikisql_processed_dataset[\"train\"] = wikisql_processed_dataset[\"train\"].shuffle().select(range(50000))\n",
    "wikisql_processed_dataset[\"validation\"] = wikisql_processed_dataset[\"validation\"].shuffle().select(range(1000))\n",
    "wikisql_processed_dataset[\"test\"] = wikisql_processed_dataset[\"test\"].shuffle().select(range(1000))\n",
    "\n",
    "wikisql_processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32d1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"translate English to SQL: \"\n",
    "max_input_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    inputs = [prefix + text for text in examples[\"question\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    \n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"human_sql\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c74658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/torch/graduation-work/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = wikisql_processed_dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f23c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f274698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "model_name = \"t5-small-english-to-sql-translation\"\n",
    "model_dir = f\"models/{model_name}\"\n",
    "\n",
    "print(transformers.__version__)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    model_dir,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"bleu\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd322b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5642/909098219.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"bleu\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "\n",
    "metric = load_metric(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, references = eval_pred\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    predictions = [pred.split() for pred in predictions]\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    references = np.where(references != -100, references, tokenizer.pad_token_id)\n",
    "    references = tokenizer.batch_decode(references, skip_special_tokens=True)\n",
    "    references = [ref.split() for ref in references]\n",
    "    references = [[ref] for ref in references]\n",
    "    \n",
    "    \n",
    "    # Compute BLEU scores\n",
    "    result = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # Extract ROUGE f1 scores\n",
    "    # result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length to metrics\n",
    "    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    # result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef0d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns an untrained model to be trained\n",
    "def model_init():\n",
    "    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a94a2ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 35473), started 0:47:28 ago. (Use '!kill 35473' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start TensorBoard before training to monitor it in progress\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '{model_dir}'/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47b7b2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/torch/graduation-work/venv/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 26:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Precisions</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.714100</td>\n",
       "      <td>0.673105</td>\n",
       "      <td>0.246682</td>\n",
       "      <td>[0.6257223656707243, 0.3915603532875368, 0.2809391814772542, 0.20580218068535824]</td>\n",
       "      <td>0.715035</td>\n",
       "      <td>0.748826</td>\n",
       "      <td>8133</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.743900</td>\n",
       "      <td>0.464659</td>\n",
       "      <td>0.386579</td>\n",
       "      <td>[0.7621794085163823, 0.5770037767519933, 0.48642055618799807, 0.39522237327636434]</td>\n",
       "      <td>0.716912</td>\n",
       "      <td>0.750299</td>\n",
       "      <td>8149</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.557100</td>\n",
       "      <td>0.387855</td>\n",
       "      <td>0.415098</td>\n",
       "      <td>[0.7820873608222195, 0.6128537571448487, 0.5258383282034668, 0.4390102455055094]</td>\n",
       "      <td>0.719724</td>\n",
       "      <td>0.752509</td>\n",
       "      <td>8173</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.334806</td>\n",
       "      <td>0.441577</td>\n",
       "      <td>[0.8002186057809084, 0.6433508432402544, 0.557106191851139, 0.4749713412304165]</td>\n",
       "      <td>0.726844</td>\n",
       "      <td>0.758125</td>\n",
       "      <td>8234</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.300943</td>\n",
       "      <td>0.458524</td>\n",
       "      <td>[0.8058475292980548, 0.6629105400577161, 0.5776644894057671, 0.49933674436232706]</td>\n",
       "      <td>0.731842</td>\n",
       "      <td>0.762085</td>\n",
       "      <td>8277</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.273629</td>\n",
       "      <td>0.470772</td>\n",
       "      <td>[0.8129600579220466, 0.6780568135034993, 0.5947192619691427, 0.5190088897295253]</td>\n",
       "      <td>0.733002</td>\n",
       "      <td>0.763005</td>\n",
       "      <td>8287</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.380600</td>\n",
       "      <td>0.257351</td>\n",
       "      <td>0.478449</td>\n",
       "      <td>[0.8162429208338354, 0.6857103712837375, 0.6050166693125894, 0.5319871673900736]</td>\n",
       "      <td>0.734392</td>\n",
       "      <td>0.764110</td>\n",
       "      <td>8299</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.246412</td>\n",
       "      <td>0.486605</td>\n",
       "      <td>[0.8209386281588448, 0.6964432284541724, 0.6160063391442155, 0.5435028248587571]</td>\n",
       "      <td>0.735666</td>\n",
       "      <td>0.765123</td>\n",
       "      <td>8310</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.233286</td>\n",
       "      <td>0.492325</td>\n",
       "      <td>[0.8258095582039244, 0.7050773231148214, 0.6247027112731885, 0.5524778594309403]</td>\n",
       "      <td>0.735318</td>\n",
       "      <td>0.764847</td>\n",
       "      <td>8307</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.221475</td>\n",
       "      <td>0.500129</td>\n",
       "      <td>[0.8316914944738106, 0.713817586018569, 0.6337760910815939, 0.5627347858752817]</td>\n",
       "      <td>0.737285</td>\n",
       "      <td>0.766412</td>\n",
       "      <td>8324</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.218342</td>\n",
       "      <td>0.503157</td>\n",
       "      <td>[0.8339745131041115, 0.7182290243235857, 0.638809749920861, 0.5690109063557729]</td>\n",
       "      <td>0.736591</td>\n",
       "      <td>0.765859</td>\n",
       "      <td>8318</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.215586</td>\n",
       "      <td>0.507958</td>\n",
       "      <td>[0.8382512344935565, 0.7255922223743667, 0.6479454228145327, 0.579294738827079]</td>\n",
       "      <td>0.734855</td>\n",
       "      <td>0.764478</td>\n",
       "      <td>8303</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.509180</td>\n",
       "      <td>[0.8368231046931408, 0.7259917920656634, 0.6497622820919176, 0.5813559322033899]</td>\n",
       "      <td>0.735666</td>\n",
       "      <td>0.765123</td>\n",
       "      <td>8310</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.203619</td>\n",
       "      <td>0.513156</td>\n",
       "      <td>[0.8406058420483231, 0.7311108074873617, 0.654059186580155, 0.5856363978191389]</td>\n",
       "      <td>0.736707</td>\n",
       "      <td>0.765952</td>\n",
       "      <td>8319</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.196533</td>\n",
       "      <td>0.517364</td>\n",
       "      <td>[0.8416946711473836, 0.7347244953627933, 0.658875552747947, 0.5920855213803451]</td>\n",
       "      <td>0.738209</td>\n",
       "      <td>0.767149</td>\n",
       "      <td>8332</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.276300</td>\n",
       "      <td>0.194761</td>\n",
       "      <td>0.517405</td>\n",
       "      <td>[0.8410945751320211, 0.7351336606655755, 0.6591914087176247, 0.5920855213803451]</td>\n",
       "      <td>0.738209</td>\n",
       "      <td>0.767149</td>\n",
       "      <td>8332</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.192017</td>\n",
       "      <td>0.517496</td>\n",
       "      <td>[0.8428141912206855, 0.7368421052631579, 0.6612826603325416, 0.5943555973659455]</td>\n",
       "      <td>0.736244</td>\n",
       "      <td>0.765583</td>\n",
       "      <td>8315</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.185658</td>\n",
       "      <td>0.519059</td>\n",
       "      <td>[0.8430477106117054, 0.7377407457997541, 0.6631862047144439, 0.5966923510618305]</td>\n",
       "      <td>0.736938</td>\n",
       "      <td>0.766136</td>\n",
       "      <td>8321</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.182849</td>\n",
       "      <td>0.522302</td>\n",
       "      <td>[0.8447488584474886, 0.7420103796776837, 0.6678266371401456, 0.6024051108605787]</td>\n",
       "      <td>0.737053</td>\n",
       "      <td>0.766228</td>\n",
       "      <td>8322</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.179501</td>\n",
       "      <td>0.522831</td>\n",
       "      <td>[0.844833793351734, 0.7425337515341607, 0.6669824727617243, 0.6009750609413088]</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>8333</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.179270</td>\n",
       "      <td>0.524392</td>\n",
       "      <td>[0.8467363865849261, 0.7457302910233639, 0.6711504984965976, 0.6057529610829103]</td>\n",
       "      <td>0.736707</td>\n",
       "      <td>0.765952</td>\n",
       "      <td>8319</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.175980</td>\n",
       "      <td>0.527994</td>\n",
       "      <td>[0.8488819427747054, 0.750068324678874, 0.6767964545742323, 0.6126363294471606]</td>\n",
       "      <td>0.736591</td>\n",
       "      <td>0.765859</td>\n",
       "      <td>8318</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.175725</td>\n",
       "      <td>0.527108</td>\n",
       "      <td>[0.8482990744079817, 0.748872796830168, 0.6755815793638233, 0.6106410979507426]</td>\n",
       "      <td>0.736707</td>\n",
       "      <td>0.765952</td>\n",
       "      <td>8319</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.173662</td>\n",
       "      <td>0.527631</td>\n",
       "      <td>[0.8505844077599711, 0.7517468146321414, 0.6783616447055089, 0.6142668428005285]</td>\n",
       "      <td>0.734392</td>\n",
       "      <td>0.764110</td>\n",
       "      <td>8299</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.169822</td>\n",
       "      <td>0.529080</td>\n",
       "      <td>[0.8498194945848375, 0.7521203830369357, 0.6798732171156894, 0.6156308851224106]</td>\n",
       "      <td>0.735666</td>\n",
       "      <td>0.765123</td>\n",
       "      <td>8310</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.167982</td>\n",
       "      <td>0.531699</td>\n",
       "      <td>[0.8517893722135197, 0.7559939717769557, 0.6853468804572155, 0.6225702962823174]</td>\n",
       "      <td>0.734392</td>\n",
       "      <td>0.764110</td>\n",
       "      <td>8299</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.164838</td>\n",
       "      <td>0.530309</td>\n",
       "      <td>[0.8511739915713425, 0.7540041067761807, 0.6819984139571769, 0.6188501413760603]</td>\n",
       "      <td>0.735087</td>\n",
       "      <td>0.764663</td>\n",
       "      <td>8305</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.163932</td>\n",
       "      <td>0.531578</td>\n",
       "      <td>[0.8529766208724994, 0.7563716086599068, 0.6849793585265164, 0.6215553038882597]</td>\n",
       "      <td>0.734277</td>\n",
       "      <td>0.764018</td>\n",
       "      <td>8298</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.162446</td>\n",
       "      <td>0.531563</td>\n",
       "      <td>[0.8523958584156032, 0.755954010402409, 0.6839517919441801, 0.6200527704485488]</td>\n",
       "      <td>0.735203</td>\n",
       "      <td>0.764755</td>\n",
       "      <td>8306</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.235200</td>\n",
       "      <td>0.159881</td>\n",
       "      <td>0.531831</td>\n",
       "      <td>[0.8508180943214629, 0.7550601750547046, 0.68393536121673, 0.6208584337349398]</td>\n",
       "      <td>0.735897</td>\n",
       "      <td>0.765307</td>\n",
       "      <td>8312</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.158729</td>\n",
       "      <td>0.532540</td>\n",
       "      <td>[0.8523506071900926, 0.7559108924422577, 0.6838689251226848, 0.6204626669174347]</td>\n",
       "      <td>0.736475</td>\n",
       "      <td>0.765767</td>\n",
       "      <td>8317</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.159880</td>\n",
       "      <td>0.531515</td>\n",
       "      <td>[0.8510280149092221, 0.7549542162088287, 0.6826025011872724, 0.6185819070904646]</td>\n",
       "      <td>0.736475</td>\n",
       "      <td>0.765767</td>\n",
       "      <td>8317</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>0.159423</td>\n",
       "      <td>0.533403</td>\n",
       "      <td>[0.8526366482061161, 0.7580071174377224, 0.6868062163019346, 0.6241990199773841]</td>\n",
       "      <td>0.735203</td>\n",
       "      <td>0.764755</td>\n",
       "      <td>8306</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.159121</td>\n",
       "      <td>0.534219</td>\n",
       "      <td>[0.85252014916396, 0.7586489812662383, 0.68715349279265, 0.6245059288537549]</td>\n",
       "      <td>0.736013</td>\n",
       "      <td>0.765399</td>\n",
       "      <td>8313</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.157254</td>\n",
       "      <td>0.535040</td>\n",
       "      <td>[0.8538405971586804, 0.7600602244730359, 0.6895020615287029, 0.6268375424048247]</td>\n",
       "      <td>0.735203</td>\n",
       "      <td>0.764755</td>\n",
       "      <td>8306</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.155223</td>\n",
       "      <td>0.535578</td>\n",
       "      <td>[0.8546658639373871, 0.7609856262833675, 0.6902458366375892, 0.6277097078228087]</td>\n",
       "      <td>0.735087</td>\n",
       "      <td>0.764663</td>\n",
       "      <td>8305</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.154546</td>\n",
       "      <td>0.535727</td>\n",
       "      <td>[0.8552314368370298, 0.7620614035087719, 0.6917090216010165, 0.6293429003021148]</td>\n",
       "      <td>0.734045</td>\n",
       "      <td>0.763834</td>\n",
       "      <td>8296</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.153073</td>\n",
       "      <td>0.535686</td>\n",
       "      <td>[0.854613346181643, 0.7614352232265132, 0.6907331006029832, 0.6286307053941909]</td>\n",
       "      <td>0.734740</td>\n",
       "      <td>0.764386</td>\n",
       "      <td>8302</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.151696</td>\n",
       "      <td>0.536104</td>\n",
       "      <td>[0.8546987951807229, 0.7619178082191781, 0.6917460317460318, 0.63]</td>\n",
       "      <td>0.734508</td>\n",
       "      <td>0.764202</td>\n",
       "      <td>8300</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.202200</td>\n",
       "      <td>0.152881</td>\n",
       "      <td>0.535935</td>\n",
       "      <td>[0.854578313253012, 0.7616438356164383, 0.6914285714285714, 0.629811320754717]</td>\n",
       "      <td>0.734508</td>\n",
       "      <td>0.764202</td>\n",
       "      <td>8300</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.537502</td>\n",
       "      <td>[0.8541516245487365, 0.7621067031463749, 0.6928684627575278, 0.6318267419962336]</td>\n",
       "      <td>0.735666</td>\n",
       "      <td>0.765123</td>\n",
       "      <td>8310</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.150394</td>\n",
       "      <td>0.536786</td>\n",
       "      <td>[0.8553868402024585, 0.7626747053987394, 0.6933947284852334, 0.6313703284258211]</td>\n",
       "      <td>0.734277</td>\n",
       "      <td>0.764018</td>\n",
       "      <td>8298</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.149823</td>\n",
       "      <td>0.537059</td>\n",
       "      <td>[0.8551823763091368, 0.7620090324346517, 0.6924052639923894, 0.6306764650461655]</td>\n",
       "      <td>0.735318</td>\n",
       "      <td>0.764847</td>\n",
       "      <td>8307</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.150119</td>\n",
       "      <td>0.536002</td>\n",
       "      <td>[0.8548698167791707, 0.7616502192982456, 0.6923443456162643, 0.6306646525679759]</td>\n",
       "      <td>0.734045</td>\n",
       "      <td>0.763834</td>\n",
       "      <td>8296</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.148750</td>\n",
       "      <td>0.536377</td>\n",
       "      <td>[0.8550078341569242, 0.7622310538577498, 0.6927108146736541, 0.6311119501604682]</td>\n",
       "      <td>0.734161</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>8297</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.192600</td>\n",
       "      <td>0.149357</td>\n",
       "      <td>0.537121</td>\n",
       "      <td>[0.8554725168756027, 0.7627467105263158, 0.6945679796696315, 0.6325528700906344]</td>\n",
       "      <td>0.734045</td>\n",
       "      <td>0.763834</td>\n",
       "      <td>8296</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.149013</td>\n",
       "      <td>0.537611</td>\n",
       "      <td>[0.8556800385495723, 0.7634570606766197, 0.6943342326614823, 0.6323335219769854]</td>\n",
       "      <td>0.734624</td>\n",
       "      <td>0.764294</td>\n",
       "      <td>8301</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>0.148721</td>\n",
       "      <td>0.538201</td>\n",
       "      <td>[0.8556974223078776, 0.7637633525061627, 0.6953348143446525, 0.6335345152772539]</td>\n",
       "      <td>0.734740</td>\n",
       "      <td>0.764386</td>\n",
       "      <td>8302</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.147995</td>\n",
       "      <td>0.537249</td>\n",
       "      <td>[0.8550602409638555, 0.7631506849315068, 0.693968253968254, 0.6320754716981132]</td>\n",
       "      <td>0.734508</td>\n",
       "      <td>0.764202</td>\n",
       "      <td>8300</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.146671</td>\n",
       "      <td>0.537144</td>\n",
       "      <td>[0.8553694106303483, 0.763327394819789, 0.6941400666984279, 0.6322446667925241]</td>\n",
       "      <td>0.734161</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>8297</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.145851</td>\n",
       "      <td>0.537572</td>\n",
       "      <td>[0.8552837691288107, 0.7633922455130839, 0.6947134465788221, 0.6329496131345537]</td>\n",
       "      <td>0.734392</td>\n",
       "      <td>0.764110</td>\n",
       "      <td>8299</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.146058</td>\n",
       "      <td>0.537336</td>\n",
       "      <td>[0.8559373116335142, 0.7639479095270734, 0.6945194598888006, 0.6326723323890463]</td>\n",
       "      <td>0.733929</td>\n",
       "      <td>0.763742</td>\n",
       "      <td>8295</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.145498</td>\n",
       "      <td>0.537733</td>\n",
       "      <td>[0.8563162970106075, 0.7646655701754386, 0.6948856416772554, 0.6329305135951662]</td>\n",
       "      <td>0.734045</td>\n",
       "      <td>0.763834</td>\n",
       "      <td>8296</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.145827</td>\n",
       "      <td>0.537359</td>\n",
       "      <td>[0.8559546769527483, 0.7638432017543859, 0.6944091486658196, 0.6325528700906344]</td>\n",
       "      <td>0.734045</td>\n",
       "      <td>0.763834</td>\n",
       "      <td>8296</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.145835</td>\n",
       "      <td>0.537621</td>\n",
       "      <td>[0.8558688840684502, 0.7637708961359276, 0.6946649730073039, 0.6328803322008305]</td>\n",
       "      <td>0.734277</td>\n",
       "      <td>0.764018</td>\n",
       "      <td>8298</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.145716</td>\n",
       "      <td>0.538315</td>\n",
       "      <td>[0.8556800385495723, 0.764415833447473, 0.6954451674337406, 0.6338426711941143]</td>\n",
       "      <td>0.734624</td>\n",
       "      <td>0.764294</td>\n",
       "      <td>8301</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.145511</td>\n",
       "      <td>0.538560</td>\n",
       "      <td>[0.8561099060014461, 0.7648670868731159, 0.696252778659892, 0.6347678369195923]</td>\n",
       "      <td>0.734277</td>\n",
       "      <td>0.764018</td>\n",
       "      <td>8298</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>0.145038</td>\n",
       "      <td>0.538329</td>\n",
       "      <td>[0.85526791089705, 0.7639972621492128, 0.6950039651070579, 0.6333647502356268]</td>\n",
       "      <td>0.735087</td>\n",
       "      <td>0.764663</td>\n",
       "      <td>8305</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.144941</td>\n",
       "      <td>0.537243</td>\n",
       "      <td>[0.8551981688953139, 0.763183125599233, 0.6936994127916204, 0.6317675910205621]</td>\n",
       "      <td>0.734624</td>\n",
       "      <td>0.764294</td>\n",
       "      <td>8301</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.144808</td>\n",
       "      <td>0.536931</td>\n",
       "      <td>[0.8553186363088785, 0.7629091905218464, 0.6930645929217585, 0.6310130164119977]</td>\n",
       "      <td>0.734624</td>\n",
       "      <td>0.764294</td>\n",
       "      <td>8301</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.144773</td>\n",
       "      <td>0.537571</td>\n",
       "      <td>[0.8553012048192771, 0.7635616438356164, 0.6944444444444444, 0.6326415094339622]</td>\n",
       "      <td>0.734508</td>\n",
       "      <td>0.764202</td>\n",
       "      <td>8300</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.144901</td>\n",
       "      <td>0.537571</td>\n",
       "      <td>[0.8553012048192771, 0.7635616438356164, 0.6944444444444444, 0.6326415094339622]</td>\n",
       "      <td>0.734508</td>\n",
       "      <td>0.764202</td>\n",
       "      <td>8300</td>\n",
       "      <td>10861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.6257223656707243, 0.3915603532875368, 0.2809391814772542, 0.20580218068535824]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.7621794085163823, 0.5770037767519933, 0.48642055618799807, 0.39522237327636434]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.7820873608222195, 0.6128537571448487, 0.5258383282034668, 0.4390102455055094]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8002186057809084, 0.6433508432402544, 0.557106191851139, 0.4749713412304165]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8058475292980548, 0.6629105400577161, 0.5776644894057671, 0.49933674436232706]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8129600579220466, 0.6780568135034993, 0.5947192619691427, 0.5190088897295253]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8162429208338354, 0.6857103712837375, 0.6050166693125894, 0.5319871673900736]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8209386281588448, 0.6964432284541724, 0.6160063391442155, 0.5435028248587571]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8258095582039244, 0.7050773231148214, 0.6247027112731885, 0.5524778594309403]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8316914944738106, 0.713817586018569, 0.6337760910815939, 0.5627347858752817]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8339745131041115, 0.7182290243235857, 0.638809749920861, 0.5690109063557729]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8382512344935565, 0.7255922223743667, 0.6479454228145327, 0.579294738827079]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8368231046931408, 0.7259917920656634, 0.6497622820919176, 0.5813559322033899]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8406058420483231, 0.7311108074873617, 0.654059186580155, 0.5856363978191389]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8416946711473836, 0.7347244953627933, 0.658875552747947, 0.5920855213803451]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8410945751320211, 0.7351336606655755, 0.6591914087176247, 0.5920855213803451]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8428141912206855, 0.7368421052631579, 0.6612826603325416, 0.5943555973659455]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8430477106117054, 0.7377407457997541, 0.6631862047144439, 0.5966923510618305]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8447488584474886, 0.7420103796776837, 0.6678266371401456, 0.6024051108605787]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.844833793351734, 0.7425337515341607, 0.6669824727617243, 0.6009750609413088]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8467363865849261, 0.7457302910233639, 0.6711504984965976, 0.6057529610829103]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8488819427747054, 0.750068324678874, 0.6767964545742323, 0.6126363294471606]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8482990744079817, 0.748872796830168, 0.6755815793638233, 0.6106410979507426]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8505844077599711, 0.7517468146321414, 0.6783616447055089, 0.6142668428005285]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8498194945848375, 0.7521203830369357, 0.6798732171156894, 0.6156308851224106]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8517893722135197, 0.7559939717769557, 0.6853468804572155, 0.6225702962823174]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8511739915713425, 0.7540041067761807, 0.6819984139571769, 0.6188501413760603]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8529766208724994, 0.7563716086599068, 0.6849793585265164, 0.6215553038882597]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8523958584156032, 0.755954010402409, 0.6839517919441801, 0.6200527704485488]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8508180943214629, 0.7550601750547046, 0.68393536121673, 0.6208584337349398]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.8523506071900926, 0.7559108924422577, 0.6838689251226848, 0.6204626669174347]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8510280149092221, 0.7549542162088287, 0.6826025011872724, 0.6185819070904646]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8526366482061161, 0.7580071174377224, 0.6868062163019346, 0.6241990199773841]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.85252014916396, 0.7586489812662383, 0.68715349279265, 0.6245059288537549]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8538405971586804, 0.7600602244730359, 0.6895020615287029, 0.6268375424048247]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8546658639373871, 0.7609856262833675, 0.6902458366375892, 0.6277097078228087]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8552314368370298, 0.7620614035087719, 0.6917090216010165, 0.6293429003021148]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.854613346181643, 0.7614352232265132, 0.6907331006029832, 0.6286307053941909]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8546987951807229, 0.7619178082191781, 0.6917460317460318, 0.63]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.854578313253012, 0.7616438356164383, 0.6914285714285714, 0.629811320754717]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8541516245487365, 0.7621067031463749, 0.6928684627575278, 0.6318267419962336]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8553868402024585, 0.7626747053987394, 0.6933947284852334, 0.6313703284258211]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8551823763091368, 0.7620090324346517, 0.6924052639923894, 0.6306764650461655]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8548698167791707, 0.7616502192982456, 0.6923443456162643, 0.6306646525679759]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8550078341569242, 0.7622310538577498, 0.6927108146736541, 0.6311119501604682]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8554725168756027, 0.7627467105263158, 0.6945679796696315, 0.6325528700906344]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8556800385495723, 0.7634570606766197, 0.6943342326614823, 0.6323335219769854]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8556974223078776, 0.7637633525061627, 0.6953348143446525, 0.6335345152772539]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8550602409638555, 0.7631506849315068, 0.693968253968254, 0.6320754716981132]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8553694106303483, 0.763327394819789, 0.6941400666984279, 0.6322446667925241]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8552837691288107, 0.7633922455130839, 0.6947134465788221, 0.6329496131345537]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8559373116335142, 0.7639479095270734, 0.6945194598888006, 0.6326723323890463]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8563162970106075, 0.7646655701754386, 0.6948856416772554, 0.6329305135951662]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8559546769527483, 0.7638432017543859, 0.6944091486658196, 0.6325528700906344]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8558688840684502, 0.7637708961359276, 0.6946649730073039, 0.6328803322008305]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8556800385495723, 0.764415833447473, 0.6954451674337406, 0.6338426711941143]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8561099060014461, 0.7648670868731159, 0.696252778659892, 0.6347678369195923]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.85526791089705, 0.7639972621492128, 0.6950039651070579, 0.6333647502356268]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8551981688953139, 0.763183125599233, 0.6936994127916204, 0.6317675910205621]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8553186363088785, 0.7629091905218464, 0.6930645929217585, 0.6310130164119977]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.8553012048192771, 0.7635616438356164, 0.6944444444444444, 0.6326415094339622]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.8553012048192771, 0.7635616438356164, 0.6944444444444444, 0.6326415094339622]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6250, training_loss=0.2762901531982422, metrics={'train_runtime': 1560.7577, 'train_samples_per_second': 32.036, 'train_steps_per_second': 4.004, 'total_flos': 696972212699136.0, 'train_loss': 0.2762901531982422, 'epoch': 1.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "688373fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-small-english-to-sql-translation/checkpoint-6200\"\n",
    "model_dir = f\"models/{model_name}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "max_input_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cbe9976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Fastest Lap FROM table_30134667_2 WHERE Date = [table_30134667_2][Date]\n"
     ]
    }
   ],
   "source": [
    "text = \"Who had the fastest lap on [table_30134667_2][Date]?\"\n",
    "\n",
    "inputs = [\"translate English to SQL: \" + text]\n",
    "\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=4, max_length=128)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_query = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c622dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT Team FROM table_1969634_1 WHERE Nickname = [table_1969634_1][Nickname]\n"
     ]
    }
   ],
   "source": [
    "text = \"How many teams have [table_1969634_1][Nickname] as a nickname?\"\n",
    "\n",
    "inputs = [\"translate English to SQL: \" + text]\n",
    "\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=4, max_length=128)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_query = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19b24de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Result FROM table_19744915_16 WHERE Cup = [table_19744915_16][Couple]\n"
     ]
    }
   ],
   "source": [
    "text = \"What is [table_19744915_16][Couple]'s result?\"\n",
    "\n",
    "inputs = [\"translate English to SQL: \" + text]\n",
    "\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=4, max_length=128)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_query = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b94d2457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Location FROM table_22670216_1 WHERE Track = [table_22670216_1][Track] AND Winning Driver = [table_22670216_1][Winning@Driver]\n"
     ]
    }
   ],
   "source": [
    "text = \"If the track is the [table_22670216_1][Track] and the winning driver is [table_22670216_1][Winning@Driver], what was the location?\"\n",
    "\n",
    "inputs = [\"translate English to SQL: \" + text]\n",
    "\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=4, max_length=128)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_query = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb20c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
